% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/cross_correlation.R
\name{cross.correlate}
\alias{cross.correlate}
\title{Estimate cross correlation of unevenly sampled time series.}
\usage{
cross.correlate(ts.1, ts.2, method = "iccf", max.lag = NULL, min.pts = 5,
  dtau = NULL, local.est = FALSE, zero.clip = NULL, use.errors = FALSE,
  one.way = FALSE, cov = FALSE, prob = 0.1, nsim = 0, peak.frac = 0.8,
  chatter = 0, plot = FALSE, ...)
}
\arguments{
\item{ts.1, ts.2}{(array or dataframe) data for time series 1 and 2.}

\item{method}{(string) use \code{"dcf"} or \code{"iccf"} (default).}

\item{min.pts}{(integer) each DCF bin must contain at least \code{min.pts} correlation coefficients.}

\item{dtau}{(float) spacing of the time delays (\code{tau}) which which CCF is estimated.}

\item{local.est}{(logical) use 'local' (not 'global') means and variances?}

\item{zero.clip}{(logical) remove pairs of points with exactly zero lag?}

\item{use.errors}{(logical) if \code{TRUE} then subtract mean square error from variances.}

\item{one.way}{(logical) (ICCF only) if TRUE then only interpolar time series 2.}

\item{cov}{(logical) if \code{TRUE} then compute covariance, not correlation coefficient.}

\item{prob}{(logical) probability level to use for confidence intervals}

\item{nsim}{(integer) number of FR/RSS simulations to run}

\item{peak.frac}{(float) only include CCF points above \code{peak.frac}*max(ccf) in centroid calculation.}

\item{chatter}{(integer) set the level of feedback.}

\item{plot}{(logical) if \code{TRUE} then a plot of the ccf vs. tau is produced.}

\item{lag.max}{(float) maximum lag at which to compute the CCF.}
}
\value{
A list with components
 \item{tau}{(array) A one dimensional array containing the lags at which the CCF is estimated.}
 \item{ccf}{(array) An array with the same dimensions as lag containing the estimated CCF.}
 \item{lower}{(array) Lower limit of CCF (see Notes).}
 \item{upper}{(array) Upper limit of CCF (see Notes).}
 \item{peak.dist}{(array) A array of length \code{nsim} containing the CCF peaks from the simulations.}
 \item{cent.dist}{(array) A array of length \code{nsim} containing the CCF centroids from the simulations.}
 \item{method}{(string) which method was used? \code{"iccf"} or \code{"dcf"}}
 The value of \code{ccf[k]} returns the estimated correlation between
 \code{ts.1$y}(t+tau) and \code{ts.2$y}(t) where tau = \code{tau[k]}. A
 strong peak at negative lags indicates the \code{ts.1} leads \code{ts.2}.
}
\description{
\code{cross.correlate} returns cross correlation data for two times series.
}
\details{
Function for estimating the cross-correlation between two time series which
may be irregularly and/or non-simultaneously sampled. The CCF is computed
using one of two methods: (1) the Discrete Correlation Function (DCF; Edelson
& Krolik 1988) or (2) the Interpolated Cross Correlation Function (ICCF; 
Gaskell & Sparke 1986). You can also produce estimates of uncertainty on the
CCF, its peak and centroid using the Flux Randomisation and Random Subsample
Selection (FR/RSS) method of Peterson et al. (1998).
}
\section{Notes}{

If only one time series is given as input then the Auto-Correlation Function
(ACF) is computed.

Local vs. global estimation: If \code{local.est = FALSE} (default) then the
correlation coefficient is computed sing the 'global' mean and variance of
each time series. If \code{local.est = TRUE} then the correlation coefficient
is computed using the 'local' mean and variance. For each lag, the mean to be
subtrated and the varaince to be divided are computed using only data points
contributing to that lag.

Simulations: Performs "flux randomisation" and "random sample selection" of 
an input time series, following Peterson et al. (2004, ApJ, 613:682-699).
Given an input data series \code{(t, y, dy)} of length \code{N} we sample 
\code{N} points with replacement. Duplicated points are ignored, so the 
ouptut is usually shorter than the input. So far this is a basic bootstrap 
procedure.

If error bars are provided: when a point is selected \code{m} times, we
decrease the error by \code{1/sqrt(m)}. See Appendix A of Peterson et al. And
after resampling in time, we then add a random Gaussian deviate to each
remaining data point, with std.dev equal to its error bar. In this way both
the times and values are randomised. If errors bars are not provided, this is
a simple bootstrap.

Peak and centroid: from the simulations we record the CCF peak and its
centroid. The centroid is the mean of \code{tau*ccf/sum(ccf)} including all
points for which \code{ccf} is higher than \code{peak.frac} of
\code{max(ccf)}.
 
Upper/lower limits and distributions: If no simulations are used (\code{nsim
= 0}) then upper/lower confidence limits on the CCF are estimated using the
method of Barlett (1955) based on the two ACFs. If simulations are used, the
confidence limits are based on the simulations.
}

\examples{
 ## Example using NGC 5548 data
 result <- cross.correlate(cont, hbeta, method = "iccf", dtau = 1, max.lag = 550)
 plot(result$tau, result$ccf, type = "l", bty = "n", xlab = "time delay", ylab = "CCF")
 grid()

 ## Examples from Venables & Ripley
 require(graphics)
 tsf <- data.frame(t = time(fdeaths), y = fdeaths)
 tsm <- data.frame(t = time(mdeaths), y = mdeaths)

 ## compute CCF using ICCF method
 result <- cross.correlate(tsm, tsf, plot = TRUE, method = "iccf")

 ## compute CCF using standard method (stats package) and compare
 result.st <- ccf(mdeaths, fdeaths, plot = FALSE)
 lines(result.st$lag, result.st$acf, col="red", lwd = 3)

}
\seealso{
\code{\link[stats]{ccf}}, \code{\link{fr.rss}}
}
